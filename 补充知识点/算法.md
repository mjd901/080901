# 算法

## 分治法

* 分治法的设计思想是将一个难以直接解决的大问题分解成一些规模较小的相同问题，以便各个击破，分而治之。

* 每个递归步骤：
    - 分解
    - 求解
    - 合并

凡是涉及到分组解决的都是`分治法`。

## 动态规划

* 动态规划算法与分治法类似，其`基本思想也是将待求解问题分解成若干个子问题，先求解子问题，然后从这些子问题的解得到原问题的解。`与分治法不同的是，适合用动态规划法求解的问题，`经分解得到的子问题往往不是独立的`。若用分治法来解这类问题，则相同的子问题会被求解多次，以至于最后解决原问题需要耗费指数级时间。


* 然而，不同子问题的数目常常只有`多项式量级`。如果`能够保存已解决的子问题的答案，在需要时再找出已求得的答案`，这样就可以避免大量的重复计算，从而得到多项式时间的算法。为了达到这个目的，可以用`一个表来记录所有已解决的子问题的答案`。不管该子问题以后是否被用到，只要它被计算过，就将其结果填入表中。这就是动态规划法的基本思路。

* 动态规划算法通常用于求解`具有某种最优性质的问题`。在这类问题中，可能会有许多可行解，每个解都对应于一个值，我们希望找到`具有最优值(最大值或最小值)的那个解`。当然，最优解可能会有多个，动态规划算法能找出其中的一个最优解。设计一个动态规划算法，通常按照以下几个步骤进行。

    - `找出最优解的性质`，并刻画其结构特征
    - `递归地定义最优解的值`。
    - 以`自底向上的方式计算出最优值`。
    - 根据计算最优值时得到的信息，`构造一个最优解`。

* 对于一个给定的问题，若其具有以下两个性质，可以考虑用动态规划法来求解。
    - `最优子结构`。如果一个问题的最优解中包含了其子问题的最优，也就是说该问题具有最优子结构。当一个问题具有最优子结构时，提示我们动态规划法可能会适用，但是此时贪心策略可能也是适用的。
    - `重叠子问题`。重叠子问题指用来解原问题的递归算法可反复地解同样的子问题，而不是总在产生新的子问题。即当一个递归算法不断地调用同一个问题时，就说该问题包含重叠子问题。

## 贪心算法

和动态规划法一样，贪心法也经常用于`解决最优化问题`。与动态规划法不同的是，贪心法在解决问题的策略上是`仅根据当前已有的信息做出选择，而且一旦做出了选择，不管将来有什么结果，这个选择都不会改变`。换而言之，贪心法`并不是从整体最优考虑，它所做出的选择只是在某种意义上的局部最优`。这种局部最优选择并不能保证总能获得全局最优解，但通常能得到较好的近似最优解。

贪心法问题一般具有两个重要的性质。
- `最优子结构`。当一个问题的最优解包含其子问题的最优解时，称此问题具有最优子结构。问题具有最优子结构是该问题可以采用动态规划法或者贪心法
求解的关键性质。
- `贪心选择性质`。指问题的整体最优解可以通过一系列局部最优的选择，即贪心选择来得到。这是贪心法和动态规划法的主要区别。证明一个问题具有贪心选择性质也是贪心法的一个难点。

## 回溯

* 概念:有“通用的解题法”之称，可以`系统地搜索一个问题的所有解或任一解`。在包含问题的所有解的解空间树中，按照`深度优先`的策略，从根节点出发搜索解空间树。搜索至任一结点时，总是`先判断该结点是否肯定不包含问题的解`，如果不包含，则跳过对以该结点为根的子树的搜索，`逐层向其祖先结点回溯`;否则，进入该子树，继续按深度优先的策略进行搜索。

* 可以理解为先进行深度优先搜索，一直向下探测，当此路不通时，返回上一层探索另外的分支，重复此步骤，这就是回溯，意为先一直探测，当不成功时再返回上一层。

* 一般用于解决`迷宫类、全排列、组合`等问题

## 分支界限法

* 原理:在分支限界法中，`每一个活结点只有一次机会成为扩展结点`。活结点一旦成为扩展结点，就`一次性产生其所有儿子结点`。在这些儿子结点中，导致`不可行解或导致非最优解的儿子结点被舍弃，其余儿子结点被加入活结点表中`。此后，从活结点表中取下一结点成为当前扩展结点，并重复上述结点扩展过程这个过程一直持续到找到所需的解或活结点表为空时为止

* 与回溯法的区别:
    - 求解目标是找出满足约束条件的一个解，或是在满足约束条件的解中找出使某一目标函数值达到`极大或极小的解，即在某种意义下的最优解`。
    - 以`广度优先或以最小耗费(最大收益)优先的方式`搜索解空间树。

+ 从活节点表中选择下一个扩展节点的类型:
    - 队列式(FIFO)分支限界法:按照`队列先进先出(FIFO)原则`选取下一个节点为扩展节点。
    - 优先队列式分支限界法:按照`优先队列中规定的优先级`选取优先级最高的节点成为当前扩展节点。

## 概率算法

* 原理: 在算法执行某些步骤时，`可以随机地选择下一步该如何进行，同时允许结果以较小的概率出现错误`，并以此为代价，`获得算法运行时间的大幅度减少(降低算法复杂度)`。

* 基本特征是对所求解问题的`同一实例用同一概率算法求解两次，可能得到完全不同的效果` 。

* 如果一个问题没有有效的确定性算法可以在一个合理的时间内给出解，但是该问题能接受小概率错误，那么采用概率算法就可以快速找到这个问题的解。

* 四类概率算法:
    - **数值概率算法**(数值问题的求解)
    - **蒙特卡洛算法**(求问题的精确解)
    - **拉斯维加斯算法**(不会得到不正确的解)
    - **舍伍德算法**(总能求得问题的一个正确解)

- 概率算法的特征:
    - 概率算法的输入包括两部分，一部分是`原问题的输入`，另一部分是一个`供算法进行随机选择的随机数序列`。
    - 概率算法在运行过程中，包括一处或多处随机选择，根据随机值来决定算法的运行路径。
    - 概率算法的`结果不能保证一定是正确的`，但能限制其出错概率。
    - 概率算法在不同的运行过程中，对于相同的输入实例可以有不同的结果因此，对于相同的输入实例，概率算法的执行时间可能不同。

## 近似算法

* 原理：解决`难解问题的一种有效策略`，其基本思想是`放弃求最优解，而用近似最优解代替最优解`，以换取算法设计上的简化和时间复杂度的降低。虽然它可能找不到一个最优解，但它总会给待求解的问题提供一个解。
* 为了具有实用性，近似算法`必须能够给出算法所产生的解与最优解之间的差别或者比例的一个界限`，它保证任意一个实例的近似最优解与最优解之间的相差程度。显然，这个差别越小，近似算法越具有实用性，

* 衡量近似算法性能两个标准:
    - `算法的时间复杂度`。近似算法的时间复杂度必须是多项式阶，的这是近似算法的基本目标。
    - `解的近似程度`。近似最优解的近似程度也是设计近似算法的重要目标。近似程度与近似算法本身、问题规模，乃至不同的输入实例有关。

## 数据挖掘类算法

分析`爆炸式增长的各类数据的技术`，以发现`隐含在这些数据中的有价值的信息和知识`。数据挖掘利用机器学习方法对多种数据进行分析和挖掘。其核心是算法，主要功能包括`分类、回归、关联规则和聚类`等。

+ 分类
    - 是一种`有监督的学习`过程，根据`历史数据`预测未来数据的模型
    - 分类的数据对象属性:一般属性、分类属性或目标属性。
    - 分类设计的数据:训练数据集、测试数据集、未知数据。
    - 数据分类的两个步骤:`学习模型`(基于训练数据集采用分类算法建立学习模型)、`应用模型`(应用测试数据集的数据到学习模型中，根据输出来评估模型的好坏以及将未知数据输入到学习模型中，预测数据的类型)
    - 分类算法:`决策树归纳(自顶向下的递归树算法)、朴素贝叶斯算法、后向传播BP、支持向量机SVM。`

频繁模式和关联规则挖掘
* 挖掘`海量数据中的频繁模式和关联规则`可以有效地指导企业发现交叉销售机会、进行`决策分析和商务管理`等。(沃尔玛-啤酒尿布故事)
* 首先要求出数据集中的频繁模式，然后由频繁模式产生关联规则。
* 关联规则挖掘算法:`类Apriori算法、基于频繁模式增长的方法如FP-growthh，使用垂直数据格式的算法，如ECLAT`。

聚类
- 是一种`无监督学习`过程。根据数据的特征，将`相似的数据对象归为一类`，不相似的数据对象归到不同的类中。物以类聚，人以群分。
- 典型算法:`基于划分的方法、基于层次的方法、基于密度的方法、基于网格的方法、基于统计模型的方法`。

## 智能优化算法

* 优化技术是一种`以数学为基础`，用于`求解各种工程问题优化解`的应用技术。
### 人工神经网络ANN
一个以`有向图为拓扑结构的动态系统，通过对连续或断续的输入作状态响应而进行信息处理`。从信息处理角度对`人脑神经元网络进行抽象`，建立某种简单模型，按不同的连接方式组成不同的网络。
### 遗传算法
源于模拟达尔文的“优胜劣汰、适者生存”的进化论和孟德尔.摩根的遗传变异理论，`在迭代过程中保持已有的结构，同时寻找更好的结构`。其本意是在`人工适应系统中设计一种基于自然的演化机制`。
### 模拟退火算法SA
求解全局优化算法。基本思想来源于物理退火过程，包括三个阶段:`加温阶段、等温阶段、冷却阶段`。将固体加温至充分高，再让其徐徐冷却，加温时，固体内部粒子随温升变为无序状，内能增大，而徐徐冷却时粒子渐趋有序，在每个温度都达到平衡态，最后在常温时达到基态，内能减为最小。
### 禁忌搜索算法TS
模拟`人类智力过程的一种全局搜索算法`，是对局部邻域搜索的一种扩展。从一个初始可行解出发，选择一系列的特定搜索方向(移动)作为试探，选择实现让特定的目标函数值变化最多的移动。为了避免陷入局部最优解，TS搜索中采用了`一种灵活的“记忆”技术，对已经进行的优化过程进行记录和选择，指导下一步的搜索方向`，这就是`Tabu表`的建立。

### 蚁群算法
- 是一种用来寻找优化路径的 `概率型算法`
- 单个蚂蚁的行为比较简单，但是蚁群整体却可以体现一些智能的行为。例如`蚁群可以在不同的环境下，寻找最短到达食物源的路径`。这是因为蚁群内的蚂蚁可以通过某种信息机制实现信息的传递。后又经进一步研究发现，蚂蚁会在其经过的路径上释放一种可以称之为`“信息素”的物质`，蚁群内的蚂蚁对“信息素”具有感知能力，它们`会沿着“信息素”浓度较高路径行走`，而每只路过的蚂蚁都会在路上留下“信息素”，这就形成一种类似正反馈的机制，这样经过一段时间后，整个蚁群就会沿着最短路径到达食物源了。
◆用`蚂蚁的行走路径表示待优化问题的可行解，整个蚂蚁群体的所有路径构成待优化问题的解空间。路径较短的蚂蚁释放的信息素量较多`，随着时间的推进较短的路径上累积的信息素浓度逐渐增高，选择该路径的蚂蚁个数也愈来愈多最终，整个蚂蚁会在正反馈的作用下集中到最佳的路径上，此时对应的便是待优化问题的最优解。

### 粒子群优化算法PSO
- 设想这样一个场景:一群鸟在随机搜索食物。在这个区域里只有一块食物。所有的鸟都不知道食物在那里。但是`他们知道当前的位置离食物还有多远`。那么找到食物的最优策略是什么呢。`最简单有效的就是搜寻目前离食物最近的的周围区域。`
- PSO从这种模型中得到启示并用于解决优化问题。PSO中， `每个优化问题的解都是搜索空间中的一只鸟`。我们称之为`“粒子”`。所有的粒子都有`一个由被优化的函数决定的适应值(fitness value)`，每个粒子还有`一个速度决定他们飞翔的方向和距离`。然后粒子们就追随当前的最优粒子在解空间中搜索。
- PS0 `初始化为一群随机粒子(随机解)`。然后通过迭代找到最优解。在每一次迭代中，粒子通过跟踪`两个"极值"`来更新自己。第一个就是`粒子本身所找到的最优解`，这个解叫做`个体极值pBest`。另一个极值是`整个种群目前找到的最优解`，这个极值是`全局极值gBest`。另外也可以不用整个种群而只是用其中一部分作为粒子的邻居，那么在所有邻居中的极值就是局部极值。


## 线性回归
线性回归是一种通过找到最佳拟合直线来预测连续值的算法。它通过最小化预测值与实际值之间的平方误差来找到最佳拟合直线。在实践中，线性回归广泛应用于预测房价、销售量等场景。
## 逻辑回归
逻辑回归是一种用于分类问题的算法，它通过将连续值转换为二元分类问题来解决分类问题。逻辑回归基于逻辑函数（sigmoid函数）将线性回归的输出转换为概率值，从而进行分类。
## 决策树
决策树是一种监督学习算法，它通过构建树状结构来对实例进行分类或回归。决策树通过递归地将数据集划分为更小的子集来构建树，每个内部节点对应一个特征的测试条件，每个分支代表一个测试结果，每个叶子节点表示一个类标签。
## 随机森林
随机森林是一种集成学习算法，它通过构建多个决策树并取平均值来进行预测。随机森林通过随机选择数据集中的一部分特征和样本构建决策树，然后对新的样本进行预测时，让每棵树分别进行预测，最后通过投票或者平均值给出最终结果。
## 梯度提升树
梯度提升树是一种用于回归和分类问题的算法，它通过构建一系列的决策树来拟合数据。梯度提升树使用梯度下降法来优化损失函数，每次迭代时都试图找到能够最小化损失函数的最佳分割点。
## 支持向量机（SVM）
支持向量机是一种分类和回归分析的算法，它通过找到能够将不同类别的样本点最大化分隔的决策边界来实现分类或回归分析。支持向量机使用核函数将输入空间映射到更高维度的特征空间，从而在特征空间中找到最佳的决策边界。
## 朴素贝叶斯
朴素贝叶斯是一种基于贝叶斯定理的分类算法，它通过计算给定特征下各个类别的概率来进行分类。朴素贝叶斯假设特征之间相互独立，利用贝叶斯定理计算出每个类别的概率，然后选择概率最大的类别作为预测结果。
## K-均值聚类
K-均值聚类是一种无监督学习的算法，它通过将数据点划分为K个聚类来进行聚类分析。K-均值聚类使用距离度量将数据点划分为K个聚类，每个聚类的中心点是该聚类中所有点的平均值。
## 层次聚类
层次聚类是一种无监督学习的算法，它通过将数据点按照层次结构进行组织来进行聚类分析。层次聚类使用距离度量将数据点按照层次结构进行组织，形成一个树状的聚类结构。
## 神经网络
神经网络是一种通过模拟人脑神经元工作方式的算法，它由多个神经元组成，能够处理复杂和抽象的映射关系。神经网络使用权重、偏置等参数来学习输入和输出之间的映射关系，并通过反向传播算法来更新参数以最小化预测误差。



## 小结
以下使用ai生成，需要自行取舍
### 监督学习算法 

| 学习类型 | 算法名称                      | 应用场景               | 描述                                                                                           |
|----------|-------------------------------|------------------------|------------------------------------------------------------------------------------------------|
| 分类     | 逻辑回归（Logistic Regression） | 二分类或多分类问题     | 使用sigmoid函数将线性模型转化为概率输出。                                                      |
| 分类     | 决策树（Decision Trees）       | 多分类问题             | 使用树形结构进行决策，基于特征的不同值进行分割。                                               |
| 分类     | 随机森林（Random Forest）      | 复杂分类问题           | 多个决策树组成的集成模型，通过投票机制得出分类结果。                                           |
| 分类     | 支持向量机（SVM）              | 二分类问题             | 寻找最大间隔的超平面作为决策边界。                                                            |
| 分类     | K近邻（K-Nearest Neighbors）    | 简单分类问题           | 基于最近邻居的多数表决进行分类。                                                              |
| 回归     | 线性回归（Linear Regression）   | 回归问题               | 使用最小二乘法寻找最佳拟合直线。                                                              |
| 回归     | 岭回归（Ridge Regression）     | 回归问题，防止过拟合   | 在线性回归基础上添加L2正则化项。                                                              |
| 回归     | LASSO回归（Lasso Regression）   | 回归问题，特征选择     | 在线性回归基础上添加L1正则化项。                                                              |
| 分类/回归| 梯度提升树（Gradient Boosting） | 复杂分类和回归问题     | 使用梯度提升技术优化弱学习者的组合。                                                          |
| 分类/回归| 深度学习（Deep Learning）       | 复杂模式识别           | 包括卷积神经网络（CNN）、循环神经网络（RNN）、变压器（Transformer）等多种模型。                |

### 无监督学习算法

| 学习类型 | 算法名称                   | 应用场景           | 描述                                                                 |
|----------|----------------------------|--------------------|----------------------------------------------------------------------|
| 聚类     | K均值聚类（K-Means）       | 数据分群           | 使用距离度量将数据划分为K个簇。                                     |
| 聚类     | 层次聚类（Hierarchical）    | 数据分群           | 产生嵌套簇的层次结构。                                               |
| 聚类     | DBSCAN                     | 密度基聚类         | 根据密度自动发现簇的数量和形状。                                     |
| 降维     | 主成分分析（PCA）           | 数据降维           | 通过线性变换保留最大方差方向。                                       |
| 降维     | t-分布随机邻域嵌入（t-SNE） | 高维数据可视化     | 适用于高维数据的低维嵌入。                                           |
| 关联规则 | Apriori算法                | 交易数据关联规则   | 发现项目之间的频繁共现关系。                                         |
| 关联规则 | FP-Growth                  | 交易数据关联规则   | 使用前缀树（FP-tree）高效地挖掘频繁项集。                             |

### 半监督学习算法

| 学习类型 | 算法名称               | 应用场景                 | 描述                                                                 |
|----------|------------------------|--------------------------|----------------------------------------------------------------------|
| 分类/回归| 标签传播（Label Propagation） | 图数据上的标签预测       | 利用图中的连通性传播标签。                                             |
| 分类/回归| 标签扩散（Label Spreading） | 图数据上的标签预测       | 类似标签传播，但使用了正则化。                                         |
| 分类     | 生成模型（Generative Models） | 生成样本及分类           | 如高斯混合模型（GMM），可用于生成样本并辅助分类。                       |
| 分类/回归| 伪标签（Pseudo Labeling）   | 大量未标注数据的利用     | 利用标注数据训练模型后，对未标注数据进行预测并作为伪标签再次训练模型。     |
| 分类/回归| 半监督支持向量机（S3VM）   | 有限标注数据下的分类问题 | 扩展传统SVM以适应半监督学习场景。                                     |

### 强化学习算法

| 学习类型 | 算法名称           | 应用场景         | 描述                                                                 |
|----------|-------------------|------------------|----------------------------------------------------------------------|
| 强化学习 | Q-Learning        | 动态决策问题     | 使用Q表来学习策略，通过奖励更新动作价值。                             |
| 强化学习 | Deep Q-Networks（DQN） | 复杂动态决策问题 | 结合深度学习和Q-learning，适用于高维输入状态空间。                     |
| 强化学习 | Policy Gradients  | 动态决策问题     | 直接优化策略参数，如REINFORCE算法。                                   |
| 强化学习 | Actor-Critic      | 动态决策问题     | 同时学习策略（Actor）和价值函数（Critic）。                           |

